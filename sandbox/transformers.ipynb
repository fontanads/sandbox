{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of the self-attention layer\n",
    "class SelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dk, n_heads, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.dk = dk\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.key = nn.Linear(d_model, dk * n_heads)  # input shape: (N, T, d_model), output shape: (N, T, dk * n_heads)\n",
    "        self.query = nn.Linear(d_model, dk * n_heads)\n",
    "        self.value = nn.Linear(d_model, dk * n_heads)\n",
    "\n",
    "        self.fc = nn.Linear(dk * n_heads, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # the mask is a boolean tensor of shape (N, T) where 1 means that the token is not masked\n",
    "        q = self.query(q)  # output shape: (N, T, dk * n_heads)\n",
    "        k = self.key(k)\n",
    "        v = self.value(v)\n",
    "\n",
    "        N = q.shape[0]  # batch size\n",
    "        T = q.shape[1]  # sequence length\n",
    "\n",
    "        # change shapes from (N, T, dk * n_heads) to (N, T, n_heads, dk) then to (N, n_heads, T, dk)\n",
    "        q = q.view(N, T, -1, self.dk).transpose(1, 2)\n",
    "        k = k.view(N, T, -1, self.dk).transpose(1, 2)\n",
    "        v = v.view(N, T, -1, self.dk).transpose(1, 2)\n",
    "\n",
    "        # compute attention scores\n",
    "        # the following line implements the algebraic multiplication of Q times K^T normalized by sqrt(dk)\n",
    "        # ignoring batch size and heads, Q is shaped (T, dk) and K is shaped (T, dk), so output is (T, T)\n",
    "        scores = q @ k.transpose(-2, -1) / np.sqrt(self.dk)  # output shape: (N, n_heads, T, T)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(\n",
    "                mask[:, None, None, :] == 0,  # the None's create two new dimensions of size 1 thus shaping it to (N, 1, 1, T) making it broadcastable\n",
    "                float('-inf')  # this is the value that will be used to replace the masked values; -inf is used because it will be replaced by 0 after the softmax\n",
    "                )\n",
    "\n",
    "        # apply softmax to get attention probabilities\n",
    "        attention = F.softmax(scores, dim=-1)  # output shape: (N, n_heads, T, T)\n",
    "\n",
    "        # apply attention to values\n",
    "        # ignoring batch size and heads, attention is shaped (T, T) and V is shaped (T, dk), so output is (T, dk)\n",
    "        out = attention @ v  # output shape: (N, n_heads, T, dk)\n",
    "\n",
    "        # change shape from (N, n_heads, T, dk) to (N, T, n_heads, dk) then to (N, T, dk * n_heads)\n",
    "        out = out.transpose(1, 2).contiguous().view(N, T, -1)\n",
    "\n",
    "        # apply linear layer\n",
    "        return self.fc(out)  # output shape: (N, T, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of the transformer block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, dk, n_heads, dropout_prob=0.1, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.mha = SelfAttention(d_model, dk, n_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, 4 * d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * d_model, d_model),\n",
    "            nn.Dropout(dropout_prob)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.ln1(x + self.mha(x, x, x, mask))\n",
    "        x = self.ln2(x + self.ffn(x))\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of positional encoding\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=2048, dropout_prob=0.1, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)  # shape: (max_len, 1)\n",
    "        exp_term = torch.arange(0, d_model, 2)\n",
    "        div_term = torch.exp(exp_term * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape (N, T, d_model)\n",
    "        x = x + self.pe[:, :x.shape[1], :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of the encoder of the transformer model\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size,\n",
    "            max_len,\n",
    "            d_model,\n",
    "            dk,\n",
    "            n_heads,\n",
    "            n_layers,\n",
    "            n_classes,\n",
    "            dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size, \n",
    "            embedding_dim=d_model)\n",
    "\n",
    "        self.pos_encoding = PositionalEncoding(\n",
    "            d_model=d_model, \n",
    "            max_len=max_len, \n",
    "            dropout_prob=dropout_prob)\n",
    "\n",
    "        self.transformer_blocks = [TransformerBlock(\n",
    "            d_model=d_model, \n",
    "            dk=dk, \n",
    "            n_heads=n_heads, \n",
    "            dropout_prob=dropout_prob\n",
    "            ) for _ in range(n_layers)]\n",
    "\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        self.fc = nn.Linear(d_model, n_classes)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x, mask)\n",
    "\n",
    "        # many to one: x is of shape (N, T, d_model) ...\n",
    "        x = x[:, 0, :]  # ... but we want to get the first token of the sequence (N, d_model)\n",
    "        # x = x.mean(dim=1)  # ... and we want to average over T to get (N, d_model)\n",
    "\n",
    "        x = self.ln(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder(\n",
    "    vocab_size=20_000,\n",
    "    max_len=1024,\n",
    "    d_model=64,\n",
    "    dk=16,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    n_classes=5,\n",
    "    dropout_prob=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device \"cpu\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (embedding): Embedding(20000, 64)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device \"{device}\"')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fonta\\AppData\\Local\\Temp\\ipykernel_8648\\1009981901.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_t = torch.tensor(x).to(device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  882, 14118,  4074,  ...,   201,  1275,  2189],\n",
       "        [ 1298, 17497, 18765,  ...,  5031, 15060,  7135],\n",
       "        [16884,  3177, 16577,  ..., 18879,  5062, 13805],\n",
       "        ...,\n",
       "        [14096, 12631,  2245,  ..., 13232,  6078, 14346],\n",
       "        [17593, 16965,  5821,  ...,  4822, 10690, 16190],\n",
       "        [ 7157,  2234, 19530,  ...,  5718,  7174,   732]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(0, 20000, (8, 512)).to(device)\n",
    "x_t = torch.tensor(x).to(device)\n",
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fonta\\AppData\\Local\\Temp\\ipykernel_8648\\3435168678.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_t = torch.tensor(mask).to(device)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.ones_like(x_t).to(device)\n",
    "mask[:, 256:] = 0\n",
    "mask_t = torch.tensor(mask).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x_t, mask_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'distilbert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/fonta/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec02f9608144cbdad1aa9de46698931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = load_dataset('glue', 'sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['sentence'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16867143dd424d8fbf25ef5266f29b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8a643ea09e4a3d980ba530eda91723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5a1e3bd1bb4749aa6ae572acd0b137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns(['sentence', 'idx'])\n",
    "tokenized_datasets = tokenized_datasets.rename_column('label', 'labels')\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_datasets['train'],\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    tokenized_datasets['validation'],\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: labels v shape: torch.Size([32])\n",
      "k: input_ids v shape: torch.Size([32, 41])\n",
      "k: attention_mask v shape: torch.Size([32, 41])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    for k, v in batch.items():\n",
    "        print(f'k: {k}', f'v shape: {v.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tokenized_datasets['train']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distilbert-base-uncased': 512,\n",
       " 'distilbert-base-uncased-distilled-squad': 512,\n",
       " 'distilbert-base-cased': 512,\n",
       " 'distilbert-base-cased-distilled-squad': 512,\n",
       " 'distilbert-base-german-cased': 512,\n",
       " 'distilbert-base-multilingual-cased': 512}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (embedding): Embedding(28996, 64)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Encoder(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    max_len=tokenizer.max_model_input_sizes[checkpoint],\n",
    "    d_model=64,\n",
    "    dk=16,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    n_classes=2,\n",
    "    dropout_prob=0.1)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 |  train_loss: 0.57149 |  test_loss: 0.55224 |  time: 0:01:12.168597\n",
      "Epoch 2/4 |  train_loss: 0.44175 |  test_loss: 0.45744 |  time: 0:01:10.180943\n",
      "Epoch 3/4 |  train_loss: 0.36602 |  test_loss: 0.42810 |  time: 0:01:14.285955\n",
      "Epoch 4/4 |  train_loss: 0.32105 |  test_loss: 0.42704 |  time: 0:01:18.730365\n"
     ]
    }
   ],
   "source": [
    "def train(model, criterion, optimizer, train_loader, val_loader, epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "\n",
    "        train_loss = 0\n",
    "        n_train = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\t\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y = model(batch['input_ids'], batch['attention_mask'])\n",
    "\n",
    "            loss = criterion(y, batch['labels'])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * batch['input_ids'].shape[0]\n",
    "            n_train += batch['input_ids'].shape[0]\n",
    "\n",
    "        train_loss /= n_train\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        n_test = 0\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\t\n",
    "\n",
    "            y = model(batch['input_ids'], batch['attention_mask'])\n",
    "\n",
    "            loss = criterion(y, batch['labels'])\n",
    "\n",
    "            test_loss += loss.item() * batch['input_ids'].shape[0]\n",
    "            n_test += batch['input_ids'].shape[0]\n",
    "        test_loss /= n_test\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}/{epochs} | ', \n",
    "            f'train_loss: {train_loss:.5f} | ',\n",
    "            f'test_loss: {test_loss:.5f} | ',\n",
    "            f'time: {dt}'\n",
    "        )\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "train_losses, test_losses = train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.88907\n",
      "Test acc: 0.80619\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "def get_loader_acc(model, loader):\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\t\n",
    "\n",
    "        y = model(batch['input_ids'], batch['attention_mask'])\n",
    "\n",
    "        n_correct += (y.argmax(dim=-1) == batch['labels']).sum().item()\n",
    "        n_total += batch['input_ids'].shape[0]\n",
    "\n",
    "    return n_correct / n_total\n",
    "\n",
    "train_acc = get_loader_acc(model, train_loader)\n",
    "test_acc = get_loader_acc(model, val_loader)\n",
    "\n",
    "print(f'Train acc: {train_acc:.5f}')\n",
    "print(f'Test acc: {test_acc:.5f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox-P7rcBpMs-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
